"""
TCGA-CESC data
----------------------------------------
"""
import os
import glob
import json
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, roc_curve


# -----------------------------
# func 
# -----------------------------

def find_features_csv():
    """
    Finds the most likely merged features CSV in the current directory.

    Priority:
      1) Common expected filenames
      2) Fallback: the newest CSV with the most columns (often the merged table)
    """
    candidates = [
        "tcga_cesc_features.csv",
        "tcga_cesc_features_table.csv",
        "features.csv",
        "final_features.csv",
        "merged_features.csv",
    ]
    for c in candidates:
        if os.path.exists(c):
            return c

    csvs = glob.glob("*.csv")
    best = None
    best_cols = -1
    best_mtime = -1
    for f in csvs:
        try:
            df_head = pd.read_csv(f, nrows=5)
            ncols = df_head.shape[1]
            mtime = os.path.getmtime(f)
            if ncols > best_cols or (ncols == best_cols and mtime > best_mtime):
                best = f
                best_cols = ncols
                best_mtime = mtime
        except Exception:
            continue
    return best


def normalize_colnames(df: pd.DataFrame) -> pd.DataFrame:
    """Strips whitespace from column names (keeps original casing)."""
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    return df


def pick_label_column(df: pd.DataFrame):
    """
    Identifies the binary label column.

    Priority:
      1) 'label' column
      2) 'vital_status' mapped Alive/Dead -> 0/1
      3) 'status' mapped Alive/Dead -> 0/1

    Returns (label_column_name, label_mode_string)
    """
    cols_lower = {c.lower(): c for c in df.columns}

    if "label" in cols_lower:
        return cols_lower["label"], "label_already"

    for key in ["vital_status", "status"]:
        if key in cols_lower:
            col = cols_lower[key]
            s = df[col].astype(str).str.strip().str.lower()
            mapped = s.map({"alive": 0, "dead": 1, "1": 1, "0": 0})

            ok = mapped.notna().mean()
            if ok >= 0.8:
                df["label"] = mapped.astype("float")
                return "label", f"mapped_from_{key}"

    raise ValueError(
        "Could not find a usable label. Expected 'label' OR vital_status/status with Alive/Dead."
    )

def ensure_outdir(outdir="outputs_phase6"):
    """Creates output folder if needed."""
    os.makedirs(outdir, exist_ok=True)
    return outdir


def plot_roc(y_true, y_prob, title, outpath):
    """Saves an ROC plot and returns the AUC."""
    fpr, tpr, _ = roc_curve(y_true, y_prob) 

    auc = roc_auc_score(y_true, y_prob)

    plt.figure()
    plt.plot(fpr, tpr, label=f"AUC = {auc:.3f}")
    plt.plot([0, 1], [0, 1], linestyle="--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(title)
    plt.legend(loc="lower right")
    
    plt.tight_layout()
    plt.savefig(outpath, dpi=200)
    plt.close()

    return auc
    


def subgroup_auc_plot(df, y_true, y_prob, subgroup_col, outpath, min_n=10):
    """
    Computes subgroup AUCs by race/ethnicity (if available).
    Groups are skipped if:
      • n < min_n
      • only one outcome class is present in that subgroup
    """
    rows = []
    for g, sub in df.groupby(subgroup_col):
        idx = sub.index
        yt = y_true.loc[idx]
        
        yp = y_prob.loc[idx]

        n = len(yt)
        if n < min_n:
            continue
        if yt.nunique() < 2:
            continue

        auc = roc_auc_score(yt, yp)
        rows.append((str(g), n, auc))

    if not rows:
        return None

    res = pd.DataFrame(rows, columns=[subgroup_col, "n", "auc"]).sort_values("auc", ascending=False)

    plt.figure()
    plt.bar(res[subgroup_col].astype(str), res["auc"])
    plt.xticks(rotation=45, ha="right")
    plt.ylim(0.0, 1.0)
    plt.xlabel(subgroup_col)
    plt.ylabel("AUC")
    plt.title(f"Subgroup AUC by {subgroup_col}")
    plt.tight_layout()
    plt.savefig(outpath, dpi=200)
    plt.close()

    return res


def risk_group_from_prob(p):
    """Bins probabilities into Low/Moderate/High."""
    if pd.isna(p):
        return np.nan
    if p < 0.33:
        return "Low"
    if p < 0.66:
        return "Moderate"
    return "High"


def guidance_logic(risk_group, age):
    """
    Simple rule-based recommendation layer.
    This is separate from model training (it just interprets outputs).
    """
    try:
        age_val = float(age) if not pd.isna(age) else np.nan
    except Exception:
        age_val = np.nan

    if risk_group == "High" and (not pd.isna(age_val)) and age_val > 35:
        
        return "Immediate Pap/HPV Test"
    elif risk_group == "Moderate":
        
        return "Schedule Screening"
    else:
        return "Routine Follow-Up"


# -----------------------------
 modelling

# -----------------------------

def main():
    outdir = ensure_outdir()

    # Load input features table
    features_path = find_features_csv()
    if not features_path:
        raise FileNotFoundError(
            "No features CSV found"
        )

    df = pd.read_csv(features_path)
    df = normalize_colnames(df)

    # Identify/ drop rows missing a label
    
    label_col, label_mode = pick_label_column(df)
    y = df[label_col].astype("float")
    keep_mask = y.notna()
    df = df.loc[keep_mask].copy()
    y = y.loc[keep_mask].astype(int)

    # Columns excluded from model training 
    
    non_feature_cols = set([
        "label",
        "status",
        "vital_status",
        "submitter_id",
        "patient_id",
        "case_id",
        "sample",
        "sample_id",
        "tumor_sample_barcode",
        "age",
        "age_at_diagnosis",
        "ajcc_pathologic_stage",
        "stage",
        "race",
        "ethnicity",
        "risk_group",
        "recommendation",
        "y_pred",
        "y_pred_rf",
    ])

    # Build numeric feature matrix 
    
    X = safe_numeric_matrix(df, drop_cols=non_feature_cols)
    if X.shape[1] < 5:
        raise ValueError(
            f"After cleaning, X has only {X.shape[1]} features. The input  may not be the merged features table."
        )

    # Train/test split (stratified, reproducible)
    X_train, X_test, y_train, y_test, df_train, df_test = train_test_split(
        X, y, df.loc[X.index], test_size=0.2, random_state=42, stratify=y
    )

    # Models (each includes median imputation )
    
    logreg = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler(with_mean=True)),
        ("model", LogisticRegression(max_iter=3000))
    ])

    rf = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("model", RandomForestClassifier(
            n_estimators=500,
            random_state=42,
            
            n_jobs=-1
        ))
    ])

    # Fit models
    logreg.fit(X_train, y_train)
    rf.fit(X_train, y_train)

    # Predict probabilities on the test set
    y_prob_lr = pd.Series(logreg.predict_proba(X_test)[:, 1], index=X_test.index, name="y_pred_lr")
    y_prob_rf = pd.Series(rf.predict_proba(X_test)[:, 1], index=X_test.index, name="y_pred_rf")

    # ROC curves + test AUC
    auc_lr = plot_roc(y_test, y_prob_lr, "ROC Curve — Logistic Regression", os.path.join(outdir, "roc_logreg.png"))
    auc_rf = plot_roc(y_test, y_prob_rf, "ROC Curve — Random Forest", os.path.join(outdir, "roc_random_forest.png"))

    # 5-fold cross-validation AUC on the full dataset
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_auc_lr = cross_val_score(logreg, X, y, cv=cv, scoring="roc_auc")
    cv_auc_rf = cross_val_score(rf, X, y, cv=cv, scoring="roc_auc")

    # Save AUC table
    auc_table = pd.DataFrame([
        {
            "model": "LogisticRegression",
            "test_auc": auc_lr,
            "cv_auc_mean": float(np.mean(cv_auc_lr)),
            "cv_auc_std": float(np.std(cv_auc_lr, ddof=1)),
            "cv_auc_all": json.dumps([float(x) for x in cv_auc_lr]),
        },
        {
            "model": "RandomForest",
            "test_auc": auc_rf,
            "cv_auc_mean": float(np.mean(cv_auc_rf)),
            "cv_auc_std": float(np.std(cv_auc_rf, ddof=1)),
            "cv_auc_all": json.dumps([float(x) for x in cv_auc_rf]),
        },
    ])
    auc_table.to_csv(os.path.join(outdir, "auc_cv_table.csv"), index=False)

    # Model comparison plot (test AUC)
    plt.figure()
    plt.bar(auc_table["model"], auc_table["test_auc"])
    plt.ylim(0.0, 1.0)
    plt.ylabel("Test AUC")
    plt.title("Model Comparison (Test AUC)")
    
    plt.xticks(rotation=20, ha="right")
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "model_comparison_test_auc.png"), dpi=200)
    plt.close()

    # Risk distribution plot (LogReg probabilities on test set)
    plt.figure()
    plt.hist(y_prob_lr.values, bins=20)
    plt.xlabel("Predicted probability (positive class)")
    plt.ylabel("Count")
    plt.title("Risk Score Distribution (LogReg, Test Set)")  
    
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "risk_distribution_logreg_test.png"), dpi=200)
    plt.close()

    # Rule-based recommendation (separate from ML)
    if age_col:
        out_test["recommendation"] = [
            guidance_logic(rg, a) for rg, a in zip(out_test["risk_group"], out_test[age_col])
        ]
    else:
        out_test["recommendation"] = [guidance_logic(rg, np.nan) for rg in out_test["risk_group"]]

    # Subgroup AUC plot/table (race preferred, else ethnicity)
    subgroup_used = None
    if "race" in out_test.columns:
        subgroup_used = "race"
    elif "ethnicity" in out_test.columns:
        subgroup_used = "ethnicity"

    if subgroup_used:
        sub_res = subgroup_auc_plot(
            out_test[[subgroup_used]].join(pd.Series(y_test, name="label")),
            
            pd.Series(y_test, index=out_test.index),
            out_test["y_pred"],
            subgroup_used,
            os.path.join(outdir, f"subgroup_auc_{subgroup_used}.png"),
            min_n=10
        )
        if sub_res is not None:
            sub_res.to_csv(os.path.join(outdir, f"subgroup_auc_{subgroup_used}.csv"), index=False)
    else:
        with open(os.path.join(outdir, "subgroup_note.txt"), "w") as f:
            f.write(
                "No 'race' or 'ethnicity' column found in the merged features file. "
                "To generate subgroup plots, merge those fields into  feature table.\n"
                
            )

   

    # Save cleaned X + y used for modeling (reproducibility)
    Xy = X.copy()
    Xy["label"] = y.values
    Xy.to_csv(os.path.join(outdir, "model_matrix_Xy.csv"), index=True)


  
    # Write a short run summary (easy to audit)
    n_samples = int(len(y))
    n_features = int(X.shape[1])

    report = f"""
 Outputs 
========================

Input features file:
- {features_path}

Label mode:
- {label_mode}

Dataset:
- Samples: {n_samples}
- Numeric features used: {n_features}

Test AUC:
- Logistic Regression: {auc_lr:.3f}
- Random Forest:       {auc_rf:.3f}

Cross-Validation (5-fold, mean ± std):
- Logistic Regression: {np.mean(cv_auc_lr):.3f} ± {np.std(cv_auc_lr, ddof=1):.3f}
- Random Forest:       {np.mean(cv_auc_rf):.3f} ± {np.std(cv_auc_rf, ddof=1):.3f}

Subgroup column used:
- {subgroup_used if subgroup_used else "None found"}

Files written to:
- {outdir}/
""".strip() + "\n"

    with open(os.path.join(outdir, "RUN_SUMMARY.txt"), "w") as f:
        f.write(report)

    print(report)
    print("Done.")


if __name__ == "__main__":
    main()
